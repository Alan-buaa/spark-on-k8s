# Default values for spark-hs.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: shirishd
  tag: spark-init:v2.2.0-kubernetes-0.5.0
  pullPolicy: IfNotPresent

service:
  type: LoadBalancer
  port: 18080

serviceAccount: default

historyServerConf:
  # to use a file system path for Spark events dir, set enablePVC to true and mention the
  # name of an already created persistent volume claim in existingClaimName.
  # The volume will be mounted on /data in the pod
  enablePVC: true
  existingClaimName: ""
  # if using file system, this should be an absolute path in the mounted volume
  # if not using file system, mention HDFS URI
  eventsDir: "/spark-events"

# any environment variables that need to be made available to history server
environment:
  # Note: do not configure Spark history events directory using SPARK_HISTORY_OPTS. It will be
  # configured by this chart based on the values in "historyServerConf" attributes in values.yaml
  # However other options can be specified.

  #SPARK_HISTORY_OPTS:
  #SPARK_DAEMON_MEMORY: 1g
  #SPARK_DAEMON_JAVA_OPTS: ...
  #SPARK_DAEMON_CLASSPATH: ...
  #SPARK_PUBLIC_DNS: ...

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}